# Core Workflow & Input Guide

A detailed explanation of how the Reading Question QC system processes inputs and generates questions.

---

## Table of Contents

1. [Overview](#overview)
2. [Input Sources](#input-sources)
3. [Step-by-Step Data Flow](#step-by-step-data-flow)
4. [Input File Specifications](#input-file-specifications)
5. [Visual Workflow Diagram](#visual-workflow-diagram)

---

## Overview

The Reading Question QC system generates reading comprehension questions from **user-provided passages**. The key insight is:

> **The passages are YOUR input â€” not generated by the system.**
> 
> You provide reading passages + metadata, and the system generates appropriate questions for those passages based on the DOK level and CCSS standard you specify.

---

## Input Sources

### The Big Picture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           USER-PROVIDED INPUTS                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚   ğŸ“„ INPUT CSV FILE (e.g., "ck_gen - questions.csv")                       â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚ passage_id | passage_text              | DOK | CCSS   | question_typeâ”‚  â”‚
â”‚   â”‚ G3-U1-P01  | "The sun rose slowly..." | 2   | RL.3.3 | MCQ          â”‚  â”‚
â”‚   â”‚ G3-U1-P01  | "The sun rose slowly..." | 1   | RL.3.1 | MCQ          â”‚  â”‚
â”‚   â”‚ G3-U1-P02  | "Scientists discovered..."| 3   | RI.3.2 | MP           â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                             â”‚
â”‚   âš ï¸  THE PASSAGES ARE YOUR INPUT - NOT GENERATED BY THE SYSTEM            â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        SYSTEM-PROVIDED RESOURCES                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ“‹ ck_gen - prompts.json    â†’  Generation templates by DOK/type           â”‚
â”‚  ğŸ“‹ ck_gen - ccss.csv        â†’  Standard descriptions lookup               â”‚
â”‚  ğŸ“‹ ck_gen - examples.csv    â†’  Template questions for pattern matching    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          QUESTION GENERATION                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
                            GENERATED OUTPUT
```

### Where Everything Comes From

| Input | Source | Notes |
|-------|--------|-------|
| **Passage text** | **YOUR CSV** | You must provide the reading passages |
| **Passage ID** | **YOUR CSV** | You define how to group questions |
| **Question specs** (DOK, CCSS, type) | **YOUR CSV** | You specify what to generate |
| **Prompts** | System file | `ck_gen - prompts.json` |
| **Standard descriptions** | System file | `ck_gen - ccss.csv` |
| **Example templates** | System file | `ck_gen - examples.csv` |
| **Generated questions** | **Claude API** | The actual output |

---

## Step-by-Step Data Flow

### Step 1: Load Your Input CSV

The system reads your input file containing passages and metadata:

```python
# In question_generator.py
def _load_questions(self) -> pd.DataFrame:
    return pd.read_csv('ck_gen - questions.csv')  # YOUR FILE
```

**Your CSV must contain:**

| Column | Source | Description |
|--------|--------|-------------|
| `passage_id` | **You provide** | Groups questions by passage |
| `passage_text` | **You provide** | The actual reading passage |
| `question_id` | **You provide** | Unique ID for each question row |
| `DOK` | **You provide** | Depth of Knowledge (1-4) |
| `CCSS` | **You provide** | Standard code (e.g., RL.3.1) |
| `question_type` | **You provide** | MCQ, SR, or MP |

---

### Step 2: For Each Row, Build the Generation Prompt

The system extracts your data and fills in the prompt template:

```python
# In question_generator.py line 176-183
def _fill_prompt_variables(self, prompt_text, row, example):
    variables = {
        'text_content': row.get('passage_text', ''),      # â† YOUR PASSAGE
        'standard_code': row.get('CCSS', ''),             # â† YOUR STANDARD
        'standard_description': self.ccss_standards.get(row.get('CCSS', ''), ''),  # â† Looked up from ccss.csv
        'existing_questions': self._get_existing_questions(row.get('passage_id', ''))  # â† Avoid duplicates
    }
```

**Variables filled into the prompt:**

| Variable | Source | Purpose |
|----------|--------|---------|
| `{text_content}` | Your `passage_text` column | The passage to generate questions about |
| `{standard_code}` | Your `CCSS` column | e.g., "RL.3.3" |
| `{standard_description}` | System lookup | Full text of the standard |
| `{existing_questions}` | Previously generated | Prevents duplicate questions |

---

### Step 3: Find a Template Example

The system searches `ck_gen - examples.csv` for a similar example question to use as a pattern:

**Priority order for matching examples:**

1. **Exact match**: Same Standard + Same DOK + Same Difficulty
2. Same Standard + Same DOK (any difficulty)
3. Same Standard + Same Difficulty (any DOK)
4. Same Standard (any DOK/difficulty)
5. Same Standard Family (RL.* or RI.*) + Same Difficulty
6. Same Standard Family (any difficulty)

**Example data from matched template:**

```python
{
    'example_question': 'What does the word "bear" mean as used in paragraph 2?',
    'example_choice_a': 'to make',
    'example_choice_b': 'to carry',
    'example_choice_c': 'to take on',
    'example_choice_d': 'to put up with',
    'example_correct': 'A'
}
```

---

### Step 4: Send to Claude API

The completed prompt sent to Claude looks like this:

```
You are generating a DOK 2 multiple choice question for grades 9-10 reading assessment
using a provided example as a template.

Text Section/Passage:
{YOUR PASSAGE TEXT HERE - from passage_text column}

Target Standard: RL.3.3 - Describe characters in a story (e.g., their traits, 
motivations, or feelings) and explain how their actions contribute to the 
sequence of events.

DOK Level: 2 (Skills and Concepts)
Question Type: Multiple Choice

Example Question (Same Standard, DOK, Difficulty):
Question: {MATCHED TEMPLATE QUESTION}
A) {template choice a}
B) {template choice b}
C) {template choice c}
D) {template choice d}
Correct Answer: {template correct answer}

Existing Questions to Avoid Duplication:
- [Previously generated questions for this passage]

Task: Use the example question as a template to create a new question for the 
provided text.

[... additional instructions for DOK level, quality requirements, output format ...]
```

---

### Step 5: Parse Response & Run QC

Claude returns a JSON response that gets parsed:

```python
# Generated result structure:
{
    'question_id': 'G3-U1-P01-Q01',
    'passage_id': 'G3-U1-P01', 
    'passage_text': 'The sun rose slowly...',  # Kept for QC
    'question_type': 'MCQ',
    'dok': 2,
    'standard': 'RL.3.3',
    'generated_content': '```json {"question": "How does Maria feel...", ...}```',
    'structured_content': {
        'question': 'How does Maria feel about the new day?',
        'choices': {
            'A': 'excited and hopeful',
            'B': 'tired and worried', 
            'C': 'angry and frustrated',
            'D': 'bored and indifferent'
        },
        'correct_answer': 'A',
        'rationale': 'The passage states Maria wondered about adventures and Max wagged excitedly...'
    }
}
```

The passage is kept attached for QC checks that need to verify text dependency and passage references.

---

### Step 6: Quality Control

Each generated question runs through 10+ QC checks:

| Check | Uses Passage? | Purpose |
|-------|---------------|---------|
| `grammatical_parallel` | No | Verify choice structure consistency |
| `plausibility` | Yes | Verify distractors are believable |
| `homogeneity` | No | Verify choices are same category |
| `specificity_balance` | No | Verify similar detail levels |
| `standard_alignment` | Yes | Verify question assesses the standard |
| `clarity_precision` | Yes | Verify clear, unambiguous wording |
| `single_correct_answer` | Yes | Verify only one correct answer |
| `passage_reference` | Yes | Verify any references are accurate |
| `text_dependency` | Yes | Verify passage reading is required |
| `length_check` | No | Verify balanced choice lengths |

---

## Input File Specifications

### Required Input CSV Format

```csv
passage_id,question_id,passage_text,DOK,CCSS,question_type
G3-U1-P01,G3-U1-P01-Q01,"The sun rose slowly over the mountains...",2,RL.3.3,MCQ
G3-U1-P01,G3-U1-P01-Q02,"The sun rose slowly over the mountains...",1,RL.3.1,MCQ
G3-U1-P02,G3-U1-P02-Q01,"Scientists have discovered a new species...",3,RI.3.2,MP
```

### Column Specifications

| Column | Required | Type | Description |
|--------|----------|------|-------------|
| `passage_id` | Yes | string | Groups questions belonging to same passage |
| `question_id` | Yes | string | Unique identifier for the question |
| `passage_text` | Yes | string | Full text of the reading passage |
| `DOK` | Yes | int (1-4) | Depth of Knowledge level |
| `CCSS` | Yes | string | Common Core standard code |
| `question_type` | Yes | string | "MCQ", "SR", or "MP" |
| `difficulty` | No | string | "Low", "Medium", or "High" |
| `grade` | No | int | Grade level (3-12) |
| `CCSS_description` | No | string | Full standard text (auto-lookup if missing) |
| `passage_title` | No | string | Title of the passage |

### Multiple Questions Per Passage

You can generate multiple questions from the same passage by using the same `passage_id`:

```csv
passage_id,question_id,passage_text,DOK,CCSS,question_type
story-1,story-1-q1,"Once upon a time...",1,RL.3.1,MCQ
story-1,story-1-q2,"Once upon a time...",2,RL.3.3,MCQ
story-1,story-1-q3,"Once upon a time...",3,RL.3.2,SR
```

The system will:
1. Track previously generated questions for each `passage_id`
2. Include them in the prompt to avoid duplicates
3. Process questions for the same passage sequentially

---

## Visual Workflow Diagram

```
YOUR INPUT CSV
     â”‚
     â”‚  â”Œâ”€ passage_text â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  â”‚                                 â”‚
     â”‚  â”‚  â”Œâ”€ DOK â”€â”€â”€â”€â”€â”                  â”‚
     â”‚  â”‚  â”‚           â†“                  â†“
     â”‚  â”‚  â”‚    Select Prompt      Fill {text_content}
     â”‚  â”‚  â”‚    (MCQ DOK 2)        in prompt template
     â”‚  â”‚  â”‚           â”‚                  â”‚
     â”‚  â”‚  â”‚           â†“                  â”‚
     â”‚  â”‚  â”‚    Find Matching             â”‚
     â”‚  â”‚  â”‚    Example Template          â”‚
     â”‚  â”‚  â”‚           â”‚                  â”‚
     â”‚  â”‚  â”‚           â†“                  â”‚
     â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚  â”‚                    â”‚
     â”‚  â”‚                    â†“
     â”‚  â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  â”‚           â”‚  Claude API   â”‚
     â”‚  â”‚           â”‚  Generation   â”‚
     â”‚  â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚  â”‚                    â”‚
     â”‚  â”‚                    â†“
     â”‚  â”‚           Generated Question
     â”‚  â”‚                    â”‚
     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ (passage kept for QC)
     â”‚                       â†“
     â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚              â”‚  QC Checks    â”‚
     â”‚              â”‚  (10+ checks) â”‚
     â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚                       â”‚
     â†“                       â†“
Final Output: Questions CSV with QC Scores
```

---

## Bulk Processing Flow

For large datasets, the bulk generator adds:

```
Load Input CSV
       â†“
Group by passage_id
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ For Each Passage (PARALLEL)         â”‚
â”‚       â†“                             â”‚
â”‚   For Each Question (SEQUENTIAL)    â”‚
â”‚       â†“                             â”‚
â”‚     Generate Question               â”‚
â”‚       â†“                             â”‚
â”‚     Run QC                          â”‚
â”‚       â†“                             â”‚
â”‚     Pass? â†’ Add to completed        â”‚
â”‚     Fail? â†’ Add to retry queue      â”‚
â”‚       â†“                             â”‚
â”‚   Update passage context            â”‚
â”‚   (so next question sees previous)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
Retry Failed Questions (up to 3x)
       â†“
Generate Output CSV
```

**Why sequential within passages?**
- Each new question needs to know what questions already exist for that passage
- Prevents generating duplicate or very similar questions
- The `{existing_questions}` variable is updated after each generation

---

## Summary

| What You Provide | What the System Does |
|------------------|---------------------|
| Reading passages | Generates questions from them |
| DOK levels | Selects appropriate prompt complexity |
| CCSS standards | Aligns questions to standards |
| Question types | Generates MCQ, SR, or MP format |
| Passage groupings | Avoids duplicate questions |

The system is a **question generator**, not a passage generator. You bring the content; it creates the assessments.



