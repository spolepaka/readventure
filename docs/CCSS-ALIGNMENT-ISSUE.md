# CCSS Alignment Issue Analysis

**Date:** December 19, 2024  
**Status:** Documented  
**Severity:** Data Quality Issue (not a system bug)

## Summary

During QC analysis of questions generated by the Question Bank Extender, we discovered that multiple questions were failing the `standard_alignment` check in sequence. Investigation revealed this is **not an API failure** but rather a **data quality issue** in the original input data where questions have incorrect Common Core State Standards (CCSS) assignments.

## Affected Questions

| Question ID | Assigned CCSS | Actual Skill Tested | Correct CCSS |
|-------------|---------------|---------------------|--------------|
| quiz_302038 | RL.3.2 | Detail recall | RL.3.1 |
| quiz_302039 | RL.3.6 | Author's purpose | RL.3.2 |
| quiz_302041 | RL.3.5 | Pattern recognition | RL.3.1/RL.3.3 |

All siblings generated from these parent questions also failed because they inherited the incorrect CCSS code.

## CCSS Standard Definitions (for reference)

| Standard | Description |
|----------|-------------|
| **RL.3.1** | Ask and answer questions to demonstrate understanding of a text, referring explicitly to the text as the basis for the answers |
| **RL.3.2** | Recount stories, including fables, folktales, and myths from diverse cultures; determine the central message, lesson, or moral and explain how it is conveyed through key details |
| **RL.3.3** | Describe characters in a story and explain how their actions contribute to the sequence of events |
| **RL.3.5** | Refer to parts of stories, dramas, and poems when writing or speaking about a text, using terms such as chapter, scene, and stanza |
| **RL.3.6** | Distinguish their own point of view from that of the narrator or those of the characters |

## Root Cause Analysis

### The Chain of Failure

```
┌─────────────────────────────────────────────────────────────────────────────────┐
│                              DATA FLOW                                          │
└─────────────────────────────────────────────────────────────────────────────────┘

1. INPUT DATA (qti_existing_questions.csv)
   ┌──────────────────────────────────────────────────────────────────────────────┐
   │ quiz_302038                                                                   │
   │ Question: "How does Alice get back to her normal size at the end?"           │
   │ CCSS: RL.3.2 ← WRONG! This is a detail recall question (should be RL.3.1)   │
   └──────────────────────────────────────────────────────────────────────────────┘
                                        │
                                        ▼
2. EXTENDER PROMPT (qb_extend prompts.json)
   ┌──────────────────────────────────────────────────────────────────────────────┐
   │ "Have the SAME DOK level, difficulty, and CCSS ({standard_code}) as the     │
   │  original"                                                                   │
   │                                                                              │
   │ The prompt TRUSTS the input CCSS is correct and propagates it.              │
   └──────────────────────────────────────────────────────────────────────────────┘
                                        │
                                        ▼
3. GENERATED SIBLINGS
   ┌──────────────────────────────────────────────────────────────────────────────┐
   │ quiz_302038_sibling_1: "What important detail does the author include..."   │
   │ quiz_302038_sibling_2: "Which two events from different parts..."           │
   │ quiz_302038_sibling_3: "According to the story, what lesson..."             │
   │ quiz_302038_sibling_4: "What key detail in the last paragraph..."           │
   │                                                                              │
   │ All inherit CCSS: RL.3.2 (still wrong!)                                     │
   └──────────────────────────────────────────────────────────────────────────────┘
                                        │
                                        ▼
4. QC VALIDATION
   ┌──────────────────────────────────────────────────────────────────────────────┐
   │ standard_alignment check compares:                                           │
   │   - What the question ACTUALLY tests                                         │
   │   - What the assigned CCSS SHOULD test                                       │
   │                                                                              │
   │ Result: MISMATCH → FAIL ❌                                                   │
   └──────────────────────────────────────────────────────────────────────────────┘
```

### Detailed Examples

#### Example 1: quiz_302038 (RL.3.2 assigned, should be RL.3.1)

**Question:** "How does Alice get back to her normal size at the end of the passage?"

**QC Response:**
> "RL.3.2 focuses on recounting stories and determining central message, lesson, or moral. This question asks students to recall a specific detail about how Alice returned to normal size, which is more aligned with RL.3.1 (asking and answering questions to demonstrate understanding, referring explicitly to text). This is a literal comprehension/detail recall question, not an assessment of understanding central message or theme."

#### Example 2: quiz_302039 (RL.3.6 assigned, should be RL.3.2)

**Question:** "This story was most likely written to..."

**QC Response:**
> "RL.3.6 requires students to distinguish their own point of view from that of the narrator or characters. This question asks about author's purpose, which aligns with RL.3.2 (recount stories and determine central message/lesson/moral), but not RL.3.6. The question does not ask students to identify or compare different points of view in the text."

#### Example 3: quiz_302041 (RL.3.5 assigned, should be RL.3.1/RL.3.3)

**Question:** "In the story, which problem happens to Alice more than once?"

**QC Response:**
> "RL.3.5 requires students to refer to parts of stories using terms like chapter, scene, and stanza. This question asks about a repeated problem/event in the story, which assesses plot comprehension and pattern recognition (more aligned with RL.3.1 or RL.3.3), not the ability to use structural terminology."

## Impact

- **19 questions failed** the `standard_alignment` check
- All failures are clustered around 3 original questions and their 4 siblings each
- The failures are **legitimate quality issues**, not system errors

## Recommendations

### Option 1: Fix at Source (Recommended)
Correct the CCSS codes in `qti_existing_questions.csv` before running the extender:

```csv
# Before
quiz_302038,RL.3.2,...

# After  
quiz_302038,RL.3.1,...
```

### Option 2: Add Pre-Validation
Add a CCSS validation step in `question_bank_extender.py` before generating siblings:

```python
def validate_ccss_alignment(question_text: str, assigned_ccss: str) -> bool:
    """Validate that the question actually tests the assigned CCSS."""
    # Call LLM to verify alignment before generating siblings
    pass
```

### Option 3: Allow CCSS Override in Siblings
Modify the extender prompt to allow the LLM to suggest a corrected CCSS:

```
If the original question's CCSS appears misaligned, suggest the correct 
CCSS in your response and generate siblings for the CORRECT standard.
```

## Key Takeaway

**The QC pipeline is working correctly.** It successfully identified questions where the assigned CCSS doesn't match what the question actually tests. The issue is upstream in the original input data quality, not in the generation or QC systems.

## Files Referenced

- Input data: `qb_extend_pipeline/inputs/qti_existing_questions.csv`
- Extender prompts: `qb_extend_pipeline/qb_extend prompts.json`
- QC prompts: `qb_extend_pipeline/qc_pipeline/config/prompts.json`
- QC results: `qb_extend_pipeline/outputs/qc_results/question_qc_v3_results.json`









