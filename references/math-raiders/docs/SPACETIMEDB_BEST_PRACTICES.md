# SpacetimeDB Rules (TypeScript + Rust)

> Opinionated, modern best practices for writing SpacetimeDB modules (Rust) and clients (TS/Rust). Keeps schemas safe, subscriptions efficient, and reducers transactional.

**Version**: 2.0  
**Last Reviewed**: 2026-01-21  
**Stack**: Rust modules (server) + TypeScript client

---

## Critical Rules (LLM: always follow)

```
ALWAYS:
- Every table needs #[primary_key]
- Use #[auto_inc] for u64 IDs (not timestamps, not random)
- Scheduled tables need: scheduled_id (PK, auto_inc) + scheduled_at (ScheduleAt)
- Return Result<(), String> from reducers for proper error handling
- Use try_insert() when duplicates are possible
- Add btree indexes on columns used in filters/joins
- Use #[reducer(init)] to initialize singleton tables on first publish
- Use ctx.rng() for randomness (deterministic, replayable)
- Use #[reducer(client_connected/client_disconnected)] for session lifecycle
- Subscribe by scope (global vs screen) and unsubscribe on unmount

NEVER:
- Don't use insert() if the row might already exist (panics → rollback)
- Don't store sensitive data in public tables
- Don't derive IDs from timestamps (collision risk)
- Don't use subscribeToAllTables() in production (use scoped queries)
- Don't subscribe to all data upfront (progressive disclosure)
- Don't forget #[auto_inc] on scheduled table's scheduled_id
- Don't use rand::thread_rng() - breaks determinism
- Don't leave ephemeral state (queues, lobbies) on disconnect
```

---

## Philosophy: The Zen of SpacetimeDB

SpacetimeDB is built on 5 core principles. Embrace them and your troubles melt away.

### 1. Everything is a Table
Your entire application state lives in tables. Users, messages, game entities, sessions—all tables. No separate cache layer, no Redis, no in-memory state to sync. **The database IS your state.**

### 2. Everything is Persistent
Don't ask for "ephemeral state"—it's a mistake. SpacetimeDB persists everything by default, even history. Write your code as if memory were infinite and permanent. Insert rows freely. Query without fear. SpacetimeDB handles the persistence.

### 3. Everything is Real-Time
Think of your client as a replica of your server. Subscribe once, and data flows automatically. No polling. No refetching. Your users should never click a refresh button.

### 4. Everything is Transactional
Every reducer runs in a transaction. Return `Ok(())` to commit, return `Err` or panic to rollback. No partial updates. No corrupted state. No cleanup code. Write your logic boldly.

### 5. Everything is Programmable
Your module is real code (Rust, C#, TypeScript) running inside the database. Need custom auth? Write a function. Need complex validation? Write a function. Never settle for less than Turing complete.

---

## TL;DR workflow

1) **Module (Rust)**
- Define tables with `#[table]`. Mark tables `public` **only** if safe for all clients to read; keep others private.
- Put business logic in `#[reducer]` functions. Each reducer runs in a transaction; return `Result<_, E>` to abort cleanly.
- Add **primary keys** everywhere; add **unique** constraints and **btree indexes** for frequent filters/joins (PK/unique are auto-indexed).
- For timers/cron, use **scheduled reducers** via a scheduled table with `scheduled_id: u64` and `scheduled_at: ScheduleAt`.
- Optional **Row Level Security (RLS)** for per-client filtering on public tables.
- Prefer **incremental migrations** (add `_v2`, backfill, dual-write) to avoid downtime.

2) **Client (TypeScript)**
- Install SDK, **generate bindings**, and connect via `DbConnection.builder()`.
- **Subscribe to specific queries**, group by lifetime, **subscribe before you unsubscribe**, avoid overlapping queries.
- Use the **client cache** (`db.table.onInsert/onUpdate/onDelete`) for UI updates; `onUpdate` requires a table **primary key**.
- Call reducers via generated `reducers.<name>(...)`.

---

## Repository shape

```
spacetimedb-app/
├─ server/            # Rust SpacetimeDB module
│  └─ src/lib.rs
├─ client-ts/         # TypeScript client
│  ├─ src/module_bindings/   # generated by `spacetime generate`
│  └─ src/main.ts
└─ client-rs/         # optional Rust client
```

---

## Rust module rules (server)

### Tables
- Use `#[table(name = foo)]`. Add `public` **only** when data can be read by all clients.
- Always define a **primary key**; add **unique** constraints and **btree indexes** for hot filters/joins.
- Keep rows small and flat to minimize serialization overhead; denormalize sparingly.

**Example**
```rust
use spacetimedb::{table, reducer, Table, ReducerContext, Identity, Timestamp, ScheduleAt};

#[table(
  name = user,
  public,
  index(name = by_name, btree = [username])
)]
pub struct User {
  #[primary_key]
  identity: Identity,
  #[unique]
  username: String,
  online: bool,
}

#[table(name = message, public)]
pub struct Message {
  #[primary_key] id: u64,
  sender: Identity,
  sent: Timestamp,
  text: String,
}
```

### Reducers
- Mark business logic with `#[reducer]`; return `Result` to abort/commit atomically.
- Prefer typed table APIs: `.insert`, `.primary_key().find`, `.unique().update`, etc.
- Use automatic reducers:
  - `#[reducer(client_connected)]` to create/mark presence.
  - `#[reducer(client_disconnected)]` to clear presence.

**Example**
```rust
#[reducer]
pub fn set_name(ctx: &ReducerContext, name: String) -> Result<(), String> {
  let trimmed = name.trim();
  if trimmed.is_empty() { return Err("empty name".into()); }
  if let Some(mut u) = ctx.db.user().identity().find(ctx.sender) {
    u.username = trimmed.to_string();
    ctx.db.user().identity().update(u);
    Ok(())
  } else {
    Err("unknown user".into())
  }
}

#[reducer(client_connected)]
pub fn client_connected(ctx: &ReducerContext) {
  if let Some(u) = ctx.db.user().identity().find(ctx.sender) {
    ctx.db.user().identity().update(User { online: true, ..u });
  } else {
    ctx.db.user().insert(User {
      identity: ctx.sender,
      username: format!("user-{:x}", ctx.sender),
      online: true
    });
  }
}
```

### Graceful inserts with `try_insert`
- `insert()` panics on constraint violations (PK/unique) — rolls back transaction.
- `try_insert()` returns `Result` — handle errors gracefully without panic.

**Use when:** Creating players, inserting data that might have duplicates.

**Example**
```rust
match ctx.db.player().try_insert(new_player) {
    Ok(inserted) => log::info!("Created player {}", inserted.id),
    Err(TryInsertError::UniqueConstraintViolation(_)) => {
        return Err("Name already taken".into());
    }
    Err(e) => return Err(format!("Insert failed: {:?}", e)),
}
```

**❌ DON'T:**
```rust
// BAD: Panics if player exists, rolls back entire transaction
ctx.db.player().insert(player);
```

### Identity vs ConnectionId
Two different identifiers in `ReducerContext`:

| | `ctx.sender` (Identity) | `ctx.connection_id` (ConnectionId) |
|---|-------------------------|-------------------------------------|
| **What** | Persistent user ID | Transient session ID |
| **Lifespan** | Forever (tied to auth token) | Single connection only |
| **On disconnect** | Still exists | Gone (becomes `None`) |
| **Use for** | Player data, ownership, auth | Session state, DC handling, rate limiting |

**Common pattern:** Track both in player table for reconnect handling:
```rust
pub struct Player {
    #[primary_key]
    id: Identity,           // Persistent
    connection_id: Option<u128>, // Current session (None if disconnected)
    // ...
}
```

### Scheduled reducers (timers / cron-like)
- Create a **scheduled table** annotated with `scheduled(reducer_name)`.
- Include `scheduled_id: u64` and `scheduled_at: ScheduleAt` (absolute `Timestamp` or repeating `Duration`).

**Example**
```rust
#[table(name = spawn_timer, scheduled(spawn_food))]
pub struct SpawnTimer {
  #[primary_key]
  #[auto_inc]
  scheduled_id: u64,
  scheduled_at: ScheduleAt, // Timestamp or Duration
}

#[reducer]
pub fn spawn_food(ctx: &ReducerContext, t: SpawnTimer) {
  // ... do work ...
  // re-schedule
  let next = ScheduleAt::from(std::time::Duration::from_secs(5));
  ctx.db.spawn_timer().insert(SpawnTimer {
    scheduled_id: t.scheduled_id,
    scheduled_at: next
  });
}
```

**❌ DON'T:**
```rust
// BAD: Missing #[auto_inc] - you must manually generate unique IDs
pub struct SpawnTimer {
  #[primary_key]
  scheduled_id: u64,  // Will fail on insert without manual ID!
  scheduled_at: ScheduleAt,
}
```

### Row Level Security (RLS)
- Use for per-client visibility on **public** tables.
- **Experimental**: enable the feature, then define SQL `Filter`s using `:sender`.

**Example**
```rust
use spacetimedb::{client_visibility_filter, Filter};

#[client_visibility_filter]
const USER_SELF: Filter = Filter::Sql("SELECT * FROM user WHERE user.identity = :sender");
```

### Views (read-only computed queries)
- Use `#[view(name = view_name, public)]` for read-only functions that compute results from tables.
- Return `Option<T>` (at-most-one row) or `Vec<T>` (multiple rows).
- Subscribable via SQL like tables: `SELECT * FROM my_view`.
- Uses `ViewContext` (has `ctx.sender`) or `AnonymousViewContext` (no sender).

**Example**
```rust
use spacetimedb::{view, ViewContext, AnonymousViewContext};

// Single row (current player)
#[view(name = my_player, public)]
fn my_player(ctx: &ViewContext) -> Option<Player> {
    ctx.db.player().identity().find(ctx.sender)
}

// Multiple rows (all players with level info)
#[view(name = all_players_with_level, public)]
fn all_players_with_level(ctx: &AnonymousViewContext) -> Vec<PlayerWithLevel> {
    ctx.db.player_level().iter()
        .filter_map(|pl| ctx.db.player().id().find(pl.player_id)
            .map(|p| PlayerWithLevel { id: p.id, name: p.name, level: pl.level }))
        .collect()
}
```

### Multi-column indexes
- Single-column: `#[index(btree)]` on a field.
- Multi-column: declare at table level.

**Example**
```rust
#[table(name = paper, index(name = url_and_country, btree(columns = [url, country])))]
struct Paper {
    url: String,
    country: String,
    venue: String
}
```

### Migrations & logging
- Prefer **incremental migrations** (add new table, backfill on read, dual-write, then cut over).
- Use `log::{info,warn,error,debug,trace}` for module logging.

**Migration pattern for adding columns:**
```rust
// Original table (can't add columns without --delete-data)
#[table(name = attack_timer, scheduled(attack_scheduled, at = scheduled_at))]
pub struct AttackTimer { /* old fields */ }

// MIGRATION WORKAROUND: Create new table with suffix
#[table(name = attack_timer_migrated, scheduled(attack_scheduled_migrated, at = scheduled_at))]
pub struct AttackTimerMigrated {
    /* old fields + new fields */
    pub new_field: bool,
}

// Deprecate old reducer
#[reducer]
fn attack_scheduled(ctx: &ReducerContext, _timer: AttackTimer) -> Result<(), String> {
    panic!("DEPRECATED - use attack_timer_migrated");
}

// New reducer handles new table
#[reducer]
fn attack_scheduled_migrated(ctx: &ReducerContext, timer: AttackTimerMigrated) -> Result<(), String> {
    // ... new logic using timer.new_field
}
```

**Convention:** Use `_v2`, `_v3`, or `_migrated` suffix. Keep old table/reducer as stub until all pending scheduled rows complete.

### Scheduled Reducer Limitations (Can't Delete/Rename)

**Critical:** SpacetimeDB does NOT support deleting or renaming scheduled reducers without `--clear-database`.

```
Error: Removing schedules is not yet implemented
```

This means:
- Once deployed, a scheduled reducer name is **permanent**
- Renaming looks like "delete old + create new" → fails
- You can modify logic inside the reducer, but not the name
- Old schedule table keeps firing even if you want to deprecate it

**Workarounds:**

1. **Consolidate:** Add new logic to existing scheduled reducer (what we did with `cleanup_abandoned_raids`)
2. **Stub:** Create new reducer, gut old one to no-op (wastes cycles but works)
3. **Wipe:** Use `--clear-database` (loses all data)

**Best practice:** Name scheduled reducers generically from the start:
- Good: `scheduled_maintenance`, `cleanup_task`, `periodic_job`
- Bad: `cleanup_abandoned_raids` (too specific, can't evolve)

---

## Advanced Rust Patterns (Production-Scale)

These patterns are battle-tested in large SpacetimeDB deployments (100k+ lines of Rust).

### Error Handling Macros

Reduce boilerplate for the common "find or return error" pattern:

```rust
#[macro_export]
macro_rules! unwrap_or_err {
    ($e:expr, $($str:tt)+) => {
        match $e {
            Some(v) => v,
            None => {
                spacetimedb::log::error!($($str)+);
                return Err(format!($($str)+))
            }
        }
    };
}

// For reducers that don't return Result
#[macro_export]
macro_rules! unwrap_or_return {
    ($e:expr, $($str:tt)+) => {
        match $e {
            Some(v) => v,
            None => {
                spacetimedb::log::error!($($str)+);
                return;
            }
        }
    };
}

// For loops - skip iteration on None
#[macro_export]
macro_rules! unwrap_or_continue {
    ($e:expr, $($str:tt)+) => {
        match $e {
            Some(v) => v,
            None => {
                spacetimedb::log::error!($($str)+);
                continue;
            }
        }
    };
}
```

**Usage:**
```rust
#[reducer]
pub fn attack(ctx: &ReducerContext, target_id: u64) -> Result<(), String> {
    let player = unwrap_or_err!(
        ctx.db.player().identity().find(ctx.sender),
        "Player not found"
    );
    let target = unwrap_or_err!(
        ctx.db.enemy().entity_id().find(target_id),
        "Target no longer exists"
    );
    // ... proceed with attack
    Ok(())
}
```

### Common Helper Functions

Create reusable helpers for cross-cutting concerns:

```rust
// Timestamp helpers - avoid Duration math everywhere
pub fn unix(now: Timestamp) -> i32 {
    now.duration_since(Timestamp::UNIX_EPOCH).unwrap().as_secs() as i32
}

pub fn unix_ms(now: Timestamp) -> u64 {
    now.duration_since(Timestamp::UNIX_EPOCH).unwrap().as_millis() as u64
}

// Actor ID helper - map Identity → entity_id with auth check
pub fn actor_id(ctx: &ReducerContext, must_be_signed_in: bool) -> Result<u64, String> {
    match ctx.db.user().identity().find(&ctx.sender) {
        Some(user) => {
            if must_be_signed_in {
                ensure_signed_in(ctx, user.entity_id)?;
            }
            Ok(user.entity_id)
        }
        None => Err("Invalid sender".into()),
    }
}

// Auth guard - reusable across reducers
pub fn ensure_signed_in(ctx: &ReducerContext, entity_id: u64) -> Result<(), String> {
    if ctx.db.signed_in_player().entity_id().find(&entity_id).is_none() {
        return Err("Not signed in".into());
    }
    Ok(())
}
```

**Usage in reducers:**
```rust
#[reducer]
pub fn submit_answer(ctx: &ReducerContext, answer: i32) -> Result<(), String> {
    let player_id = actor_id(ctx, true)?; // Requires sign-in
    // ... logic
    Ok(())
}
```

### Role-Based Authorization

For admin/teacher/moderator features:

```rust
#[derive(SpacetimeType, Clone, Copy, PartialEq, Eq, PartialOrd, Ord)]
pub enum Role {
    Player = 0,
    Teacher = 1,
    Admin = 2,
}

#[table(name = identity_role)]
pub struct IdentityRole {
    #[primary_key]
    pub identity: Identity,
    pub role: Role,
}

pub fn has_role(ctx: &ReducerContext, identity: &Identity, required: Role) -> bool {
    // Dev mode bypasses auth for testing
    if let Some(config) = ctx.db.config().version().find(&0) {
        if config.env == "dev" { return true; }
    }
    
    match ctx.db.identity_role().identity().find(identity) {
        Some(entry) if entry.role as i32 >= required as i32 => true,
        _ => false,
    }
}
```

**Usage:**
```rust
#[reducer]
pub fn admin_reset_player(ctx: &ReducerContext, player_id: u64) -> Result<(), String> {
    if !has_role(ctx, &ctx.sender, Role::Admin) {
        return Err("Admin access required".into());
    }
    // ... admin logic
    Ok(())
}
```

### Scheduled Tables with Context

Add payload fields beyond just `scheduled_id` and `scheduled_at`:

```rust
#[table(
    name = attack_timer, 
    public, 
    scheduled(attack_scheduled, at = scheduled_at),
    index(name = by_attacker, btree(columns = [attacker_id]))  // Index for cancellation!
)]
pub struct AttackTimer {
    #[primary_key]
    #[auto_inc]
    pub scheduled_id: u64,
    pub scheduled_at: ScheduleAt,
    
    // Context for the scheduled reducer
    pub attacker_id: u64,
    pub target_id: u64,
    pub ability_id: i32,
    pub damage_multiplier: f32,
}

#[reducer]
fn attack_scheduled(ctx: &ReducerContext, timer: AttackTimer) -> Result<(), String> {
    // Full context available - no extra lookups needed
    let damage = calculate_damage(ctx, timer.attacker_id, timer.ability_id);
    apply_damage(ctx, timer.target_id, damage * timer.damage_multiplier);
    Ok(())
}
```

**Tip:** Add indexes on scheduled tables to support cancellation queries (e.g., "cancel all pending attacks from this player").

### Singleton Tables (Config/Globals)

Use `version: 0` as a stable primary key for single-row tables:

```rust
#[table(name = config)]
pub struct Config {
    #[primary_key]
    pub version: i32,  // Always 0 - singleton pattern
    pub env: String,
    pub agents_enabled: bool,
    pub maintenance_mode: bool,
}

#[table(name = globals)]
pub struct Globals {
    #[primary_key]
    pub version: i32,  // Always 0
    pub entity_pk_counter: u64,  // Global entity ID generator
    pub server_start_time: Timestamp,
}

// Usage: always find version 0
let config = ctx.db.config().version().find(&0).unwrap();
```

**Initialize singletons with `#[reducer(init)]`:**
```rust
#[reducer(init)]
pub fn init(ctx: &ReducerContext) {
    // Runs once on first publish - set up singletons
    ctx.db.config().insert(Config {
        version: 0,
        env: "prod".into(),
        agents_enabled: true,
        maintenance_mode: false,
    });
    ctx.db.globals().insert(Globals {
        version: 0,
        entity_pk_counter: 0,
        server_start_time: ctx.timestamp,
    });
}
```

**Note:** `init` only runs on first publish. For migrations or re-initialization, call a separate reducer manually.

### Deterministic Randomness

Use `ctx.rng()` for reproducible random values (important for replays/debugging):

```rust
use spacetimedb::rand::Rng;

#[reducer]
pub fn spawn_loot(ctx: &ReducerContext, enemy_id: u64) -> Result<(), String> {
    let mut rng = ctx.rng();  // Seeded deterministically
    
    let drop_chance: f32 = rng.gen();  // 0.0 to 1.0
    if drop_chance > 0.7 {
        let item_id = rng.gen_range(1..=100);
        ctx.db.loot().insert(Loot { enemy_id, item_id });
    }
    Ok(())
}
```

**❌ DON'T:** Use `rand::thread_rng()` or external randomness — breaks determinism.

### Entity ID Factory

For games with many entity types sharing IDs, use a global counter:

```rust
pub fn create_entity(ctx: &ReducerContext) -> u64 {
    let mut globals = ctx.db.globals().version().find(&0).unwrap();
    globals.entity_pk_counter += 1;
    let pk = globals.entity_pk_counter;
    ctx.db.globals().version().update(globals);
    pk
}

// Usage
let entity_id = create_entity(ctx);
ctx.db.player().insert(Player { entity_id, ... });
ctx.db.inventory().insert(Inventory { entity_id, ... });
ctx.db.health().insert(Health { entity_id, ... });
```

**Advantage:** Same entity_id across related tables enables consistent lookups.

**When to use which ID strategy:**
| Strategy | When to use |
|----------|-------------|
| `#[auto_inc]` on table PK | Single-table entities, simplest option |
| Global counter (above) | Multi-table entities needing shared IDs |
| Timestamp-derived | Demo/prototypes only (collision risk) |

### Computed Cache Tables

Pre-compute expensive queries into a cache table:

```rust
#[table(name = location_cache)]
pub struct LocationCache {
    #[primary_key]
    pub version: i32,  // Singleton pattern
    pub spawn_locations: Vec<Coordinates>,
    pub trading_post_locations: Vec<Coordinates>,
    // ... pre-computed data
}

impl LocationCache {
    pub fn build(ctx: &ReducerContext) {
        let spawn_locations = ctx.db.terrain()
            .iter()
            .filter(|t| t.is_spawn_point)
            .map(|t| t.coordinates)
            .collect();
        
        ctx.db.location_cache().try_insert(LocationCache {
            version: 0,
            spawn_locations,
            // ...
        }).ok();
    }
}
```

**When to use:** World generation results, static data aggregations, anything computed once and read many times.

### Vec Fields: When They're OK

`Vec<T>` fields trade update granularity for query simplicity:

| Use Vec | Use Separate Table |
|---------|-------------------|
| Updates are infrequent | High-frequency updates to individual items |
| Always need the whole list | Often query/update single items |
| Small lists (< 100 items) | Large collections |
| Parent-child always fetched together | Need to subscribe to items independently |

**Example (OK):**
```rust
// Inventory pockets - always displayed together, updates are batch operations
pub struct Inventory {
    entity_id: u64,
    pockets: Vec<Pocket>,  // OK: load all pockets when viewing inventory
}
```

**Example (Avoid):**
```rust
// Chat messages - high frequency, independent subscriptions needed
pub struct ChatRoom {
    room_id: u64,
    messages: Vec<Message>,  // BAD: every new message re-serializes entire history
}
// Better: separate Message table with room_id index
```

### Connect/Disconnect Lifecycle

Handle player sessions with special lifecycle reducers:

```rust
#[table(name = session, public)]
pub struct Session {
    #[primary_key]
    pub identity: Identity,
    pub connection_id: ConnectionId,
    pub connected_at: Timestamp,
    pub last_active: Timestamp,
}

#[table(name = player, public)]
pub struct Player {
    #[primary_key]
    pub identity: Identity,
    pub name: String,
    pub is_online: bool,  // Derived from session existence
}

// Called automatically when client connects
#[reducer(client_connected)]
pub fn on_connect(ctx: &ReducerContext) {
    let identity = ctx.sender;
    let conn_id = ctx.connection_id.expect("connect always has connection_id");
    
    // Create or update session
    if let Some(mut session) = ctx.db.session().identity().find(&identity) {
        session.connection_id = conn_id;
        session.last_active = ctx.timestamp;
        ctx.db.session().identity().update(session);
    } else {
        ctx.db.session().insert(Session {
            identity,
            connection_id: conn_id,
            connected_at: ctx.timestamp,
            last_active: ctx.timestamp,
        });
    }
    
    // Mark player online
    if let Some(mut player) = ctx.db.player().identity().find(&identity) {
        player.is_online = true;
        ctx.db.player().identity().update(player);
    }
}

// Called automatically when client disconnects
#[reducer(client_disconnected)]
pub fn on_disconnect(ctx: &ReducerContext) {
    let identity = ctx.sender;
    
    // Remove session
    if let Some(session) = ctx.db.session().identity().find(&identity) {
        ctx.db.session().identity().delete(&identity);
    }
    
    // Mark player offline
    if let Some(mut player) = ctx.db.player().identity().find(&identity) {
        player.is_online = false;
        ctx.db.player().identity().update(player);
    }
    
    // Clean up ephemeral state (matchmaking queues, typing indicators, etc.)
    cleanup_ephemeral_state(ctx, &identity);
}

fn cleanup_ephemeral_state(ctx: &ReducerContext, identity: &Identity) {
    // Remove from matchmaking queue
    if let Some(queue_entry) = ctx.db.matchmaking_queue().identity().find(identity) {
        ctx.db.matchmaking_queue().identity().delete(identity);
    }
    // Cancel pending actions, leave lobbies, etc.
}
```

**Key points:**
- `#[reducer(client_connected)]` and `#[reducer(client_disconnected)]` are special — SpacetimeDB calls them automatically
- `ctx.connection_id` is `Some` in connect, can be `None` in scheduled reducers
- Session table tracks active connections; Player table is persistent
- Always clean up ephemeral state (queues, lobbies, typing indicators) on disconnect

**Reconnection handling:**
```rust
// Client reconnects with same identity but new connection_id
// on_connect handles this by updating the session row
// No special handling needed if you use identity as session PK
```

---

## TypeScript client rules

### Setup & generated bindings
- Install SDK: `npm install spacetimedb` (note: `@clockworklabs/spacetimedb-sdk` is deprecated as of v1.4.0).
- Generate bindings:
  ```sh
  spacetime generate --lang typescript \
    --out-dir client-ts/src/module_bindings \
    --project-path server
  ```
- Import generated `DbConnection`, `reducers`, and `db` helpers from `module_bindings`.

### Connection & auth
- Build a connection with `DbConnection.builder()`.
- Set `withUri`, `withModuleName`, optional `withToken`.
- Capture the token in `onConnect` and persist it (e.g., `localStorage`).

**Snippet**
```ts
import { DbConnection } from './module_bindings';

const conn = DbConnection.builder()
  .withUri(import.meta.env.VITE_STDB_URI)
  .withModuleName(import.meta.env.VITE_STDB_NAME)
  .onConnect((ctx, identity, token) => localStorage.setItem('stdb_token', token))
  .onConnectError((ctx, err) => console.error(err))
  .withToken(localStorage.getItem('stdb_token') ?? undefined)
  .build();
```

### Subscriptions (must-do's)
- Subscribe to **specific queries**; avoid `subscribeToAllTables()` in production (convenience-only and not cancelable).
- **Group by lifetime** (global vs screen-scoped).
- **Subscribe before you unsubscribe** to avoid gaps; avoid overlapping queries.
- Subscription SQL constraints:
  - Must select **entire rows** from exactly **one table** (`SELECT table.*`); projections not allowed.
  - At most **one JOIN** (two tables total).
  - Both join columns must be **indexed**.
  - No arithmetic in `WHERE`.

**Snippet**
```ts
// Lifetime group 1: app-wide
const globalSub = conn.subscriptionBuilder()
  .onApplied(() => console.log('global ready'))
  .onError((_, err) => console.error(err))
  .subscribe([
    "SELECT * FROM user",
    "SELECT * FROM message"
  ]);

// Lifetime group 2: screen-scope
let chatSub = conn.subscriptionBuilder()
  .subscribe([`SELECT * FROM message WHERE sender = ${conn.identity}`]);

// Widen scope without losing data
const nextSub = conn.subscriptionBuilder().subscribe([`SELECT * FROM message`]);
if (chatSub.isActive()) chatSub.unsubscribe();
chatSub = nextSub;
```

### Client cache & callbacks
- Use `db.table.onInsert/onUpdate/onDelete` for UI updates.
- `onUpdate` requires the table to have a **primary key**.
- Unique indexes are exposed for fast lookups (e.g., `.username().find(name)`).

**Snippet**
```ts
const { db, reducers } = conn;

db.user.onInsert(({ db }, row) => { /* ... */ });
db.user.onUpdate(({ db }, prev, next) => { /* ... */ }); // requires PK

const me = db.user.username().find("alice"); // via unique index
```

### Reducer calls
- Call reducers via generated `reducers.<name>(...args)`; handle results and UI notifications as needed.

### Subscription strategies

**By scope:**
| Scope | When to use | Example |
|-------|-------------|---------|
| Global | Data needed everywhere | `user`, `config`, `my_player` |
| Screen | Data for current view only | `chat_messages WHERE room_id = X` |
| Ephemeral | Brief operations | `matchmaking_queue` during search |

**Pattern: Progressive disclosure**
```ts
// Start narrow, widen on demand
const mySub = conn.subscriptionBuilder().subscribe([
  `SELECT * FROM player WHERE identity = '${conn.identity}'`
]);

// User opens leaderboard → subscribe to more
function openLeaderboard() {
  const leaderboardSub = conn.subscriptionBuilder().subscribe([
    `SELECT * FROM player`  // All players for ranking
  ]);
  // mySub still active - no gap in my player data
}
```

**Pattern: Room-based (multiplayer)**
```ts
// Subscribe only to current game room
function joinRoom(roomId: string) {
  return conn.subscriptionBuilder().subscribe([
    `SELECT * FROM player WHERE room_id = '${roomId}'`,
    `SELECT * FROM game_state WHERE room_id = '${roomId}'`,
  ]);
}

// Clean up on leave
function leaveRoom(sub: SubscriptionHandle) {
  sub.unsubscribe();
}
```

**❌ DON'T:**
```ts
// BAD: Subscribes to everything - slow, wasteful
conn.subscriptionBuilder().subscribe([
  "SELECT * FROM player",
  "SELECT * FROM game_state", 
  "SELECT * FROM chat_message",
  // ...every table
]);
```

### Optimistic updates

Show immediate feedback, reconcile with server:

```ts
const [pendingAnswers, setPendingAnswers] = useState<Set<number>>(new Set());

function submitAnswer(problemId: number, answer: number) {
  // Optimistic: show as pending immediately
  setPendingAnswers(prev => new Set(prev).add(problemId));
  
  // Call reducer
  reducers.submitAnswer(problemId, answer);
}

// Reconcile when server confirms
db.player_answer.onInsert((ctx, row) => {
  if (row.identity === conn.identity) {
    setPendingAnswers(prev => {
      const next = new Set(prev);
      next.delete(row.problem_id);
      return next;
    });
  }
});
```

**When to use optimistic updates:**
| Use optimistic | Don't use optimistic |
|----------------|---------------------|
| Local-only feedback (button states) | Shared state others see |
| Low-stakes actions | Money/inventory changes |
| Fast expected response | Slow operations |

### React integration patterns

**Hook: useSpacetimeDB**
```ts
function useSpacetimeDB() {
  const [conn, setConn] = useState<DbConnection | null>(null);
  const [isConnected, setIsConnected] = useState(false);
  
  useEffect(() => {
    const connection = DbConnection.builder()
      .withUri(import.meta.env.VITE_STDB_URI)
      .withModuleName(import.meta.env.VITE_STDB_NAME)
      .withToken(localStorage.getItem('stdb_token') ?? undefined)
      .onConnect((ctx, identity, token) => {
        localStorage.setItem('stdb_token', token);
        setIsConnected(true);
      })
      .onDisconnect(() => setIsConnected(false))
      .build();
    
    setConn(connection);
    return () => connection.disconnect();
  }, []);
  
  return { conn, isConnected };
}
```

**Hook: useTable (reactive)**
```ts
function useTable<T>(
  table: { onInsert: Function; onUpdate: Function; onDelete: Function; iter: () => Iterable<T> }
): T[] {
  const [rows, setRows] = useState<T[]>(() => [...table.iter()]);
  
  useEffect(() => {
    const refresh = () => setRows([...table.iter()]);
    
    const unsubs = [
      table.onInsert(refresh),
      table.onUpdate(refresh),
      table.onDelete(refresh),
    ];
    
    return () => unsubs.forEach(u => u());
  }, [table]);
  
  return rows;
}

// Usage
function PlayerList() {
  const players = useTable(db.player);
  return <ul>{players.map(p => <li key={p.id}>{p.name}</li>)}</ul>;
}
```

**Pattern: Subscription lifecycle in components**
```ts
function ChatRoom({ roomId }: { roomId: string }) {
  const [messages, setMessages] = useState<Message[]>([]);
  
  useEffect(() => {
    // Subscribe when component mounts
    const sub = conn.subscriptionBuilder()
      .onApplied(() => setMessages([...db.message.iter()]))
      .subscribe([`SELECT * FROM message WHERE room_id = '${roomId}'`]);
    
    const unsub = db.message.onInsert((_, msg) => {
      if (msg.room_id === roomId) {
        setMessages(prev => [...prev, msg]);
      }
    });
    
    // Unsubscribe when component unmounts
    return () => {
      sub.unsubscribe();
      unsub();
    };
  }, [roomId]);
  
  return <MessageList messages={messages} />;
}
```

---

## Performance & scalability checklist

**Schema**
- [ ] Every table has a **primary key**.
- [ ] Add **unique** constraints where needed; they are auto-indexed.
- [ ] Add **btree indexes** on frequent filters and on **both sides of JOINs**.

**SQL (subscriptions)**
- [ ] Single-table row selection (`SELECT table.*`).
- [ ] ≤ 1 JOIN; indexed join columns.
- [ ] No arithmetic in `WHERE`.

**Subscriptions (client)**
- [ ] Group by **lifetime**.
- [ ] **Subscribe before unsubscribe**.
- [ ] Avoid **overlap**.
- [ ] Avoid `subscribeToAllTables` in production.

**Data shape**
- [ ] Keep rows small to reduce payload and memory.

**Scheduling**
- [ ] Use scheduled tables + `ScheduleAt`; re-schedule inside reducers for periodic jobs.

---

## Security & auth

- **Public vs Private tables**: Clients can read **public** tables; keep sensitive tables private and expose mutations via reducers.
- **RLS**: Enable (experimental) to restrict row visibility for public tables; write filters using `:sender`.
- **Tokens & identity**: Provide a token with `withToken`; receive a private token in `onConnect` and persist for reconnection.

---

## CLI essentials

```sh
spacetime init --lang rust server                         # scaffold module
spacetime publish --project-path server my-db-name        # build & upload
spacetime logs my-db-name -f                              # stream logs
spacetime sql my-db-name "SELECT * FROM message"          # ad-hoc query
spacetime call my-db-name reducerName ...                 # invoke reducer
spacetime generate --lang typescript \
  --out-dir client-ts/src/module_bindings --project-path server
```

---

## Minimal starter templates

### `server/src/lib.rs` (Rust module)
```rust
use spacetimedb::{table, reducer, Table, ReducerContext, Identity};

#[table(name = todo, public)]
pub struct Todo {
  #[primary_key]
  #[auto_inc]
  id: u64,
  owner: Identity,
  title: String,
  done: bool,
}

#[reducer]
pub fn add_todo(ctx: &ReducerContext, title: String) {
  ctx.db.todo().insert(Todo { id: 0, owner: ctx.sender, title, done: false });
  // ✅ id: 0 is replaced by auto-increment
  // ❌ DON'T: let id = timestamp.to_bytes()... (collision risk)
}

#[reducer]
pub fn set_done(ctx: &ReducerContext, id: u64, done: bool) -> Result<(), String> {
  if let Some(t) = ctx.db.todo().id().find(id) {
    if t.owner != ctx.sender { return Err("not your todo".into()); }
    ctx.db.todo().id().update(Todo { done, ..t });
    Ok(())
  } else {
    Err("missing".into())
  }
}
```

### `client-ts/src/main.ts`
```ts
import { DbConnection } from "./module_bindings";

const conn = DbConnection.builder()
  .withUri(import.meta.env.VITE_STDB_URI)
  .withModuleName(import.meta.env.VITE_STDB_NAME)
  .onConnect((_, __, token) => localStorage.setItem("token", token))
  .withToken(localStorage.getItem("token") ?? undefined)
  .build();

const sub = conn.subscriptionBuilder()
  .onApplied(() => console.log("subscribed"))
  .onError((_, err) => console.error(err))
  .subscribe([`SELECT * FROM todo WHERE owner = ${conn.identity}`]);

conn.db.todo.onInsert(({ db }, row) => console.log("new", row));
conn.db.todo.onUpdate(({ db }, prev, next) => console.log("changed", next)); // requires PK

conn.reducers.add_todo("Read SpacetimeDB docs!");
```

---

## Debugging & CLI Quick Reference

```bash
# View logs (most common)
spacetime logs math-raiders -f              # Follow logs in real-time
spacetime logs math-raiders -n 100          # Last 100 lines

# Query data
spacetime sql math-raiders "SELECT * FROM player"
spacetime sql math-raiders "SELECT COUNT(*) as n FROM fact_mastery"

# Check module status
spacetime status math-raiders

# Publish (keeps data)
spacetime publish math-raiders --project-path server

# Publish with data wipe (schema changes)
spacetime publish math-raiders --project-path server --delete-data

# Generate client bindings
spacetime generate --lang typescript --out-dir client/src/module_bindings --project-path server
```

---

## Common pitfalls (and fixes)

### Server-side (Rust)
- **Reducer panics on insert** → Use `try_insert()` for graceful constraint handling.
- **Can't update row** → Tables need a `#[primary_key]` for `.update()` to work.
- **`ctx.connection_id` is None** → Normal for scheduled reducers (no client connection).
- **Data not persisting** → Reducer returned `Err` or panicked → transaction rolled back.

### Client-side (TypeScript)
- **`onUpdate` doesn't fire** → Add a **primary key** to the table.
- **JOIN in subscription is slow/invalid** → Ensure only one JOIN and **indexes on both join columns**.
- **Projection in subscription** → Not allowed; subscribe to `table.*` and project locally.
- **Using `subscribeToAllTables` in prod** → Avoid; it's convenience-only and cannot be canceled.
- **Listeners firing multiple times** → Forgot to call `removeOnInsert/Update/Delete` on cleanup.
- **Stale data after reconnect** → Re-subscribe after connection; old subscriptions are gone.

### Schema & Deployment
- **Leaky public data** → Use **RLS** or keep tables private and expose via reducers.
- **Downtime due to schema change** → Use **incremental migrations** (add `_v2`, backfill, dual-write).
- **Can't publish (schema mismatch)** → Use `--delete-data` flag (wipes data!) or migrate incrementally.
- **Adding column to scheduled table** → Create `_migrated` table; old scheduled rows still fire old reducer.
- **Entity not found after lookup** → Use `unwrap_or_err!` macro for consistent error handling + logging.
- **Repeating auth checks** → Extract `has_role()` and `ensure_signed_in()` helpers.
- **Stale session data after disconnect** → Use `#[reducer(client_disconnected)]` to clean up.

---

## Advanced: Scoped Subscriptions + Listener Cleanup

### Core Principle
**Subscriptions filter what's in cache. Listeners react to changes.**

- Subscription SQL (`WHERE grade = 3`) controls which rows enter client cache
- Listeners (`onInsert/onUpdate/onDelete`) **only fire for rows in cache**
- No need to filter in listener callbacks - subscription already did it
- **Must cleanup listeners** when scope ends (e.g., component unmount) to prevent duplicates

### Key Facts

1. **Listeners only fire for cached rows**
   - Subscribe to `WHERE grade = 3` → only grade 3 rows trigger callbacks
   - Don't filter again in the callback - it's redundant

2. **Cleanup prevents memory leaks**
   - Call `removeOnInsert/Update/Delete` when scope ends
   - Without cleanup, listeners persist and accumulate on each re-initialization

3. **Multiple subscriptions merge**
   - Cache contains union of all active subscriptions
   - Example: `WHERE id = '${myId}'` + `WHERE raid_id = ${raidId}` = both in cache

### Pattern: Scoped Subscription (React + Large Tables)

**SpacetimeDB semantics:** `onInsert` fires for EVERY row during initial subscription.
See: https://spacetimedb.com/docs/sdks/typescript/subscription-semantics

**The problem:** React state handlers do O(n) work per call (spread into new array).
With 50k rows: 50k calls × O(n) = **O(n²) freeze**.

Official examples use O(1) handlers (`console.log`) which don't have this issue.
For React state with large tables, set up listeners **inside** `onApplied`:

```typescript
const sub = conn.subscriptionBuilder()
  .onApplied((ctx) => {
    // Initial data from cache (called once, not per-row)
    const data = Array.from(ctx.db.myTable.iter());
    setData(data);
    
    // Set up listeners AFTER initial sync - they only fire for NEW changes going forward
    conn.db.myTable.onInsert((_, row) => setData(prev => [...prev, row]));
    conn.db.myTable.onUpdate((_, old, row) => setData(prev => prev.map(r => r.id === row.id ? row : r)));
    conn.db.myTable.onDelete((_, row) => setData(prev => prev.filter(r => r.id !== row.id)));
  })
  .subscribe([`SELECT * FROM my_table WHERE field = ${filterValue}`]);

// Cleanup (when scope/component ends)
sub.unsubscribe();
conn.db.myTable.removeOnInsert(handler);
conn.db.myTable.removeOnUpdate(handler);
conn.db.myTable.removeOnDelete(handler);
```

**For small tables or O(1) handlers:** Listeners outside `onApplied` is fine (official pattern).

### Common Mistakes

❌ **DON'T filter in listener when subscription already filters:**
```typescript
sub.subscribe([`SELECT * FROM users WHERE grade = 3`])
users.onInsert((ctx, user) => {
  if (user.grade === 3) { // REDUNDANT!
    // ...
  }
});
```

✅ **DO trust the subscription:**
```typescript
sub.subscribe([`SELECT * FROM users WHERE grade = 3`])
users.onInsert(() => {
  // Cache only has grade 3, no filter needed
  const data = Array.from(conn.db.users.iter());
});
```

❌ **DON'T forget cleanup:**
```typescript
// Setup listeners...
conn.db.table.onInsert(handler);
// Scope ends without removeOnInsert(handler) = memory leak!
```

✅ **DO always clean up:**
```typescript
// Setup
conn.db.table.onInsert(handler);

// Later, when scope ends
conn.db.table.removeOnInsert(handler);
```

### When to Use Global vs Scoped Listeners

| Approach | Use Case | Example |
|----------|----------|---------|
| **Global listeners** | App-wide state, never removed | Current player profile, global notifications |
| **Scoped listeners** | Component/screen-specific data | Filtered leaderboards, chat room messages, modal data |

For framework-specific implementations (React hooks, Vue composables, etc.), see your framework's integration patterns.
